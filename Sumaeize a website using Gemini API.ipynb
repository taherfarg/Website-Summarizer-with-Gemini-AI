{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07136ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cda3f88",
   "metadata": {},
   "source": [
    "####first let's import the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900b2a8-6384-4316-8aaa-5e519fca4254",
   "metadata": {},
   "source": [
    "# Connecting to GEMINI (or Ollama)\n",
    "\n",
    "The next cell is where we load in the environment variables in your `.env` file and connect to GEMINI\n",
    ".  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "019974d9-f3ad-4a8a-b5f9-0a3719aea2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the Gemini API with the API key\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fc84b-0815-4f40-99ab-d9a5da6bda91",
   "metadata": {},
   "source": [
    "# Let's make a quick call to a Frontier model to get started, as a preview!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a58394bf-1e45-46af-9bfd-01e24da6f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! It's wonderful to hear from you! Welcome! I'm excited to be your first ever message recipient.\n",
      "\n",
      "How can I help you today? What's on your mind? I'm ready for anything you'd like to talk about, ask about, or create!\n"
     ]
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with these messages is this easy. Any problems, head over to the Troubleshooting notebook.\n",
    "# Example: Generate a simple response from Gemini\n",
    "model = genai.GenerativeModel('models/gemini-2.5-flash-lite')\n",
    "prompt = \"Hello, Gemini! This is my first ever message to you! Hi!\"\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa190e5-cb31-456a-96cc-db109919cd78",
   "metadata": {},
   "source": [
    "## OK onwards with our first project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e793b2-6775-426a-a139-4848291d0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.favicon = None\n",
    "        self.images = []\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # Extract title\n",
    "            self.title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "            # Extract favicon\n",
    "            favicon_link = soup.find('link', rel='icon') or soup.find('link', rel='shortcut icon')\n",
    "            if favicon_link and favicon_link.get('href'):\n",
    "                favicon_url = favicon_link['href']\n",
    "                if favicon_url.startswith('//'):\n",
    "                    favicon_url = 'https:' + favicon_url\n",
    "                elif favicon_url.startswith('/'):\n",
    "                    from urllib.parse import urlparse\n",
    "                    parsed = urlparse(url)\n",
    "                    favicon_url = f\"{parsed.scheme}://{parsed.netloc}{favicon_url}\"\n",
    "                self.favicon = favicon_url\n",
    "\n",
    "            # Extract main images (limit to first few)\n",
    "            img_tags = soup.find_all('img', limit=5)\n",
    "            for img in img_tags:\n",
    "                img_src = img.get('src', '')\n",
    "                if img_src:\n",
    "                    if img_src.startswith('//'):\n",
    "                        img_src = 'https:' + img_src\n",
    "                    elif img_src.startswith('/'):\n",
    "                        from urllib.parse import urlparse\n",
    "                        parsed = urlparse(url)\n",
    "                        img_src = f\"{parsed.scheme}://{parsed.netloc}{img_src}\"\n",
    "                    elif not img_src.startswith('http'):\n",
    "                        from urllib.parse import urlparse, urljoin\n",
    "                        parsed = urlparse(url)\n",
    "                        img_src = urljoin(url, img_src)\n",
    "\n",
    "                    # Only add reasonable sized images\n",
    "                    if img.get('width', '').isdigit() and int(img.get('width', 0)) > 100:\n",
    "                        self.images.append({\n",
    "                            'url': img_src,\n",
    "                            'alt': img.get('alt', ''),\n",
    "                            'width': img.get('width', ''),\n",
    "                            'height': img.get('height', '')\n",
    "                        })\n",
    "\n",
    "            # Remove irrelevant elements for text extraction\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True) if soup.body else \"\"\n",
    "\n",
    "        except Exception as e:\n",
    "            self.title = \"Error loading website\"\n",
    "            self.text = f\"Could not load content from {url}. Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Technique Auto-Selects Training Examples to Speed Up Fine-Tuning\n",
      "✨ New course! Enroll in\n",
      "Building and Evaluating Data Agents\n",
      "Explore Courses\n",
      "AI Newsletter\n",
      "The Batch\n",
      "Andrew's Letter\n",
      "Data Points\n",
      "ML Research\n",
      "Blog\n",
      "✨ AI Dev x NYC\n",
      "Community\n",
      "Forum\n",
      "Events\n",
      "Ambassadors\n",
      "Ambassador Spotlight\n",
      "Resources\n",
      "Company\n",
      "About\n",
      "Careers\n",
      "Contact\n",
      "Start Learning\n",
      "Weekly Issues\n",
      "Andrew's Letters\n",
      "Data Points\n",
      "ML Research\n",
      "Business\n",
      "Science\n",
      "Culture\n",
      "Hardware\n",
      "AI Careers\n",
      "About\n",
      "Subscribe\n",
      "The Batch\n",
      "Machine Learning Research\n",
      "Article\n",
      "Faster Reinforcement Learning\n",
      "New technique auto-selects training examples to speed up fine-tuning\n",
      "Machine Learning Research\n",
      "Large Language Models (LLMs)\n",
      "Reinforcement Learning\n",
      "Published\n",
      "Sep 24, 2025\n",
      "Reading time\n",
      "2\n",
      "min read\n",
      "Share\n",
      "Loading the\n",
      "Elevenlabs Text to Speech\n",
      "AudioNative Player...\n",
      "Fine-tuning large language models via reinforcement learning is computationally expensive, but researchers found a way to streamline the process.\n",
      "What’s new:\n",
      "Qinsi Wang and colleagues at UC Berkeley and Duke University developed\n",
      "GAIN-RL\n",
      ", a method that accelerates reinforcement learning fine-tuning by selecting training examples automatically based on the model’s own internal signals, specifically the angles between vector representations of tokens. The code is\n",
      "available\n",
      "on GitHub.\n",
      "Key insight:\n",
      "The cosine similarity between a model’s vector representations of input tokens governs the magnitude of gradient updates during training. Specifically, the sum of those similarities that enter a model’s classification layer, called the angle concentration, governs the magnitude of gradient updates. Examples with higher angle concentration produce larger gradient updates. The magnitude of a gradient update in turn determines the effectiveness of a given training example: The larger the update, the more the model learns. Prioritizing the most-effective examples before transitioning to less-effective ones enhances training efficiency while adding little preprocessing overhead.\n",
      "How it works:\n",
      "The authors separately fine-tuned Qwen 2.5 1.5B, Qwen 2.5 7B, and Llama 3.2 3B using the\n",
      "GRPO\n",
      "reinforcement learning algorithm with examples ordered according to their angle concentration. The datasets included math problems in\n",
      "GSM8K\n",
      "and\n",
      "AMC 23\n",
      ", and coding problems in\n",
      "LiveCodeBench\n",
      "and\n",
      "HumanEval+\n",
      ".\n",
      "Given a training set, the authors calculated the angle concentration of each example by performing a single forward pass on the entire dataset. They sorted examples from highest to lowest angle concentration.\n",
      "They fine-tuned the models, focusing first on examples with the highest angle concentrations and shifting toward lower angle concentrations as training progressed. They tracked the models’ learning according to accuracy and the angle concentration on each batch of data. They shifted the focus more toward less-effective examples as the model learned and shifted less when it struggled.\n",
      "They continued training for 200 epochs.\n",
      "Results:\n",
      "The authors compared models that were fine-tuned using GAIN-RL with counterparts that used GRPO performed on randomly ordered examples. GAIN-RL generally accelerated learning by a factor of 2.5.\n",
      "Whether the task involved math or coding, GAIN-RL took 70 to 80 training epochs to match the performance of fine-tuning using typical GRPO for 200 epochs.\n",
      "For instance, on GSM8K, Qwen 2.5 Math Instruct 7B after GAIN-RL fine-tuning achieved 92.0 percent accuracy after 70 epochs. The version fine-tuned on typical GRPO needed 200 epochs to reach the same performance.\n",
      "Why it matters:\n",
      "Many strategies for ordering training examples rely on external, often expensive heuristics based on their difficulty, for example judgments by human annotators or a proprietary LLM. By using a simple signal generated by the model itself, this method provides a direct and efficient way to identify the most effective examples, making reinforcement learning much faster.\n",
      "We’re thinking:\n",
      "Ordering training examples is much older than applying reinforcement learning to fine-tuning large language models. Applying earlier methods to more recent approaches holds many advances in machine learning!\n",
      "Share\n",
      "Subscribe to The Batch\n",
      "Stay updated with weekly AI News and Insights delivered to your inbox\n",
      "Courses\n",
      "The Batch\n",
      "Community\n",
      "Careers\n",
      "About\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out. Change the website and add print statements to follow along.\n",
    "\n",
    "ed = Website(\"https://www.deeplearning.ai/the-batch/new-technique-auto-selects-training-examples-to-speed-up-fine-tuning/\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a478a0c-2c53-48ff-869c-4d08199931e1",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "\n",
    "Models like gemini have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26448ec4-5c00-4204-baec-7df91d11ff2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website titled New Technique Auto-Selects Training Examples to Speed Up Fine-Tuning\n",
      "The contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\n",
      "\n",
      "✨ New course! Enroll in\n",
      "Building and Evaluating Data Agents\n",
      "Explore Courses\n",
      "AI Newsletter\n",
      "The Batch\n",
      "Andrew's Letter\n",
      "Data Points\n",
      "ML Research\n",
      "Blog\n",
      "✨ AI Dev x NYC\n",
      "Community\n",
      "Forum\n",
      "Events\n",
      "Ambassadors\n",
      "Ambassador Spotlight\n",
      "Resources\n",
      "Company\n",
      "About\n",
      "Careers\n",
      "Contact\n",
      "Start Learning\n",
      "Weekly Issues\n",
      "Andrew's Letters\n",
      "Data Points\n",
      "ML Research\n",
      "Business\n",
      "Science\n",
      "Culture\n",
      "Hardware\n",
      "AI Careers\n",
      "About\n",
      "Subscribe\n",
      "The Batch\n",
      "Machine Learning Research\n",
      "Article\n",
      "Faster Reinforcement Learning\n",
      "New technique auto-selects training examples to speed up fine-tuning\n",
      "Machine Learning Research\n",
      "Large Language Models (LLMs)\n",
      "Reinforcement Learning\n",
      "Published\n",
      "Sep 24, 2025\n",
      "Reading time\n",
      "2\n",
      "min read\n",
      "Share\n",
      "Loading the\n",
      "Elevenlabs Text to Speech\n",
      "AudioNative Player...\n",
      "Fine-tuning large language models via reinforcement learning is computationally expensive, but researchers found a way to streamline the process.\n",
      "What’s new:\n",
      "Qinsi Wang and colleagues at UC Berkeley and Duke University developed\n",
      "GAIN-RL\n",
      ", a method that accelerates reinforcement learning fine-tuning by selecting training examples automatically based on the model’s own internal signals, specifically the angles between vector representations of tokens. The code is\n",
      "available\n",
      "on GitHub.\n",
      "Key insight:\n",
      "The cosine similarity between a model’s vector representations of input tokens governs the magnitude of gradient updates during training. Specifically, the sum of those similarities that enter a model’s classification layer, called the angle concentration, governs the magnitude of gradient updates. Examples with higher angle concentration produce larger gradient updates. The magnitude of a gradient update in turn determines the effectiveness of a given training example: The larger the update, the more the model learns. Prioritizing the most-effective examples before transitioning to less-effective ones enhances training efficiency while adding little preprocessing overhead.\n",
      "How it works:\n",
      "The authors separately fine-tuned Qwen 2.5 1.5B, Qwen 2.5 7B, and Llama 3.2 3B using the\n",
      "GRPO\n",
      "reinforcement learning algorithm with examples ordered according to their angle concentration. The datasets included math problems in\n",
      "GSM8K\n",
      "and\n",
      "AMC 23\n",
      ", and coding problems in\n",
      "LiveCodeBench\n",
      "and\n",
      "HumanEval+\n",
      ".\n",
      "Given a training set, the authors calculated the angle concentration of each example by performing a single forward pass on the entire dataset. They sorted examples from highest to lowest angle concentration.\n",
      "They fine-tuned the models, focusing first on examples with the highest angle concentrations and shifting toward lower angle concentrations as training progressed. They tracked the models’ learning according to accuracy and the angle concentration on each batch of data. They shifted the focus more toward less-effective examples as the model learned and shifted less when it struggled.\n",
      "They continued training for 200 epochs.\n",
      "Results:\n",
      "The authors compared models that were fine-tuned using GAIN-RL with counterparts that used GRPO performed on randomly ordered examples. GAIN-RL generally accelerated learning by a factor of 2.5.\n",
      "Whether the task involved math or coding, GAIN-RL took 70 to 80 training epochs to match the performance of fine-tuning using typical GRPO for 200 epochs.\n",
      "For instance, on GSM8K, Qwen 2.5 Math Instruct 7B after GAIN-RL fine-tuning achieved 92.0 percent accuracy after 70 epochs. The version fine-tuned on typical GRPO needed 200 epochs to reach the same performance.\n",
      "Why it matters:\n",
      "Many strategies for ordering training examples rely on external, often expensive heuristics based on their difficulty, for example judgments by human annotators or a proprietary LLM. By using a simple signal generated by the model itself, this method provides a direct and efficient way to identify the most effective examples, making reinforcement learning much faster.\n",
      "We’re thinking:\n",
      "Ordering training examples is much older than applying reinforcement learning to fine-tuning large language models. Applying earlier methods to more recent approaches holds many advances in machine learning!\n",
      "Share\n",
      "Subscribe to The Batch\n",
      "Stay updated with weekly AI News and Insights delivered to your inbox\n",
      "Courses\n",
      "The Batch\n",
      "Community\n",
      "Careers\n",
      "About\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(ed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea211b5f-28e1-4a86-8e52-c0b7677cadcc",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAI expects to receive messages in a particular structure.\n",
    "Many of the other APIs share this structure:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "```\n",
    "To give you a preview, the next 2 cells make a rather simple call - we won't stretch the mighty GPT (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f25dcd35-0cd0-4235-9f64-ac37ed9eaaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21ed95c5-7001-47de-a36d-1d6673b403ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4\n"
     ]
    }
   ],
   "source": [
    "# To give you a preview -- calling Gemini with system and user messages:\n",
    "\n",
    "import google.generativeai as genai\n",
    "model = genai.GenerativeModel('models/gemini-2.5-flash-lite')\n",
    "chat = model.start_chat(history=[])\n",
    "response = chat.send_message(messages[-1][\"content\"])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e8d78-ce4c-4b05-aa8e-17050c82bb47",
   "metadata": {},
   "source": [
    "## And now let's build useful messages for Gemini, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36478464-39ee-485c-9f3f-6a4e458dbc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.'}, {'role': 'user', 'content': \"You are looking at a website titled New Technique Auto-Selects Training Examples to Speed Up Fine-Tuning\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\n✨ New course! Enroll in\\nBuilding and Evaluating Data Agents\\nExplore Courses\\nAI Newsletter\\nThe Batch\\nAndrew's Letter\\nData Points\\nML Research\\nBlog\\n✨ AI Dev x NYC\\nCommunity\\nForum\\nEvents\\nAmbassadors\\nAmbassador Spotlight\\nResources\\nCompany\\nAbout\\nCareers\\nContact\\nStart Learning\\nWeekly Issues\\nAndrew's Letters\\nData Points\\nML Research\\nBusiness\\nScience\\nCulture\\nHardware\\nAI Careers\\nAbout\\nSubscribe\\nThe Batch\\nMachine Learning Research\\nArticle\\nFaster Reinforcement Learning\\nNew technique auto-selects training examples to speed up fine-tuning\\nMachine Learning Research\\nLarge Language Models (LLMs)\\nReinforcement Learning\\nPublished\\nSep 24, 2025\\nReading time\\n2\\nmin read\\nShare\\nLoading the\\nElevenlabs Text to Speech\\nAudioNative Player...\\nFine-tuning large language models via reinforcement learning is computationally expensive, but researchers found a way to streamline the process.\\nWhat’s new:\\nQinsi Wang and colleagues at UC Berkeley and Duke University developed\\nGAIN-RL\\n, a method that accelerates reinforcement learning fine-tuning by selecting training examples automatically based on the model’s own internal signals, specifically the angles between vector representations of tokens. The code is\\navailable\\non GitHub.\\nKey insight:\\nThe cosine similarity between a model’s vector representations of input tokens governs the magnitude of gradient updates during training. Specifically, the sum of those similarities that enter a model’s classification layer, called the angle concentration, governs the magnitude of gradient updates. Examples with higher angle concentration produce larger gradient updates. The magnitude of a gradient update in turn determines the effectiveness of a given training example: The larger the update, the more the model learns. Prioritizing the most-effective examples before transitioning to less-effective ones enhances training efficiency while adding little preprocessing overhead.\\nHow it works:\\nThe authors separately fine-tuned Qwen 2.5 1.5B, Qwen 2.5 7B, and Llama 3.2 3B using the\\nGRPO\\nreinforcement learning algorithm with examples ordered according to their angle concentration. The datasets included math problems in\\nGSM8K\\nand\\nAMC 23\\n, and coding problems in\\nLiveCodeBench\\nand\\nHumanEval+\\n.\\nGiven a training set, the authors calculated the angle concentration of each example by performing a single forward pass on the entire dataset. They sorted examples from highest to lowest angle concentration.\\nThey fine-tuned the models, focusing first on examples with the highest angle concentrations and shifting toward lower angle concentrations as training progressed. They tracked the models’ learning according to accuracy and the angle concentration on each batch of data. They shifted the focus more toward less-effective examples as the model learned and shifted less when it struggled.\\nThey continued training for 200 epochs.\\nResults:\\nThe authors compared models that were fine-tuned using GAIN-RL with counterparts that used GRPO performed on randomly ordered examples. GAIN-RL generally accelerated learning by a factor of 2.5.\\nWhether the task involved math or coding, GAIN-RL took 70 to 80 training epochs to match the performance of fine-tuning using typical GRPO for 200 epochs.\\nFor instance, on GSM8K, Qwen 2.5 Math Instruct 7B after GAIN-RL fine-tuning achieved 92.0 percent accuracy after 70 epochs. The version fine-tuned on typical GRPO needed 200 epochs to reach the same performance.\\nWhy it matters:\\nMany strategies for ordering training examples rely on external, often expensive heuristics based on their difficulty, for example judgments by human annotators or a proprietary LLM. By using a simple signal generated by the model itself, this method provides a direct and efficient way to identify the most effective examples, making reinforcement learning much faster.\\nWe’re thinking:\\nOrdering training examples is much older than applying reinforcement learning to fine-tuning large language models. Applying earlier methods to more recent approaches holds many advances in machine learning!\\nShare\\nSubscribe to The Batch\\nStay updated with weekly AI News and Insights delivered to your inbox\\nCourses\\nThe Batch\\nCommunity\\nCareers\\nAbout\"}]\n"
     ]
    }
   ],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "print(messages_for(ed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0",
   "metadata": {},
   "source": [
    "## Time to bring it together - the API for OpenAI is very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the Gemini API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    chat = model.start_chat(history=[])\n",
    "    response = chat.send_message(messages_for(website)[-1][\"content\"])\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05e38d41-dfa4-4b20-9c96-c46ea75d9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Summary: New Technique Auto-Selects Training Examples to Speed Up Fine-Tuning\\n\\nThis article introduces **GAIN-RL**, a new method developed by researchers at UC Berkeley and Duke University that significantly speeds up the fine-tuning of large language models (LLMs) using reinforcement learning.\\n\\nThe core innovation of GAIN-RL lies in its **automatic selection of training examples**. Instead of relying on external, often costly, heuristics to determine example importance, GAIN-RL utilizes the LLM\\'s own internal signals – specifically, the **angles between vector representations of tokens**. The \"angle concentration\" of an example, derived from these token angles, directly correlates with the magnitude of gradient updates during training. Examples with higher angle concentration lead to larger updates and thus, faster learning.\\n\\n**How it works:**\\n\\n1.  **Calculate Angle Concentration:** A single forward pass over the entire dataset is performed to calculate the angle concentration for each training example.\\n2.  **Sort Examples:** Examples are then sorted from highest to lowest angle concentration.\\n3.  **Prioritized Training:** The LLM is fine-tuned using reinforcement learning (specifically, the GRPO algorithm), beginning with examples of the highest angle concentration and gradually progressing to those with lower concentrations. The focus shifts more towards less-effective examples as the model learns.\\n4.  **Tracking Progress:** Model learning is monitored using accuracy and angle concentration on data batches.\\n\\n**Results:**\\n\\nGAIN-RL demonstrated a **2.5x acceleration in learning** compared to traditional GRPO fine-tuning with randomly ordered examples. Models fine-tuned with GAIN-RL reached the same performance levels in **70-80 training epochs** as those trained with standard GRPO for **200 epochs**, regardless of whether the tasks involved math or coding problems.\\n\\n**Significance:**\\n\\nThis method offers a **direct and efficient way to identify the most impactful training examples** without the need for expensive external resources. By leveraging the model\\'s own signals, GAIN-RL makes reinforcement learning-based LLM fine-tuning considerably faster and more accessible. The article highlights how applying established techniques from older areas of machine learning to newer approaches can lead to significant advancements.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://www.deeplearning.ai/the-batch/new-technique-auto-selects-training-examples-to-speed-up-fine-tuning/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a summary of the website's content:\n",
       "\n",
       "The website discusses a new technique called **GAIN-RL** developed by researchers at UC Berkeley and Duke University that significantly speeds up the process of fine-tuning large language models (LLMs) using reinforcement learning.\n",
       "\n",
       "**Key Points:**\n",
       "\n",
       "*   **Problem:** Fine-tuning LLMs with reinforcement learning is computationally expensive and time-consuming.\n",
       "*   **Solution:** GAIN-RL automatically selects training examples based on the model's internal signals, specifically the angles between vector representations of tokens. Examples that result in larger gradient updates (higher \"angle concentration\") are prioritized.\n",
       "*   **How it Works:** The method involves a single forward pass to calculate the angle concentration of each training example, sorting them from highest to lowest. The fine-tuning process then focuses on high-concentration examples first, gradually shifting to lower-concentration ones as the model learns.\n",
       "*   **Results:** GAIN-RL generally accelerated learning by a factor of 2.5, achieving comparable performance in 70-80 training epochs to traditional methods requiring 200 epochs. For example, a Qwen 2.5 model reached 92.0% accuracy on GSM8K in 70 epochs with GAIN-RL, whereas the standard method needed 200 epochs.\n",
       "*   **Significance:** This technique is more efficient than existing methods that often rely on external, costly heuristics (like human annotators or proprietary LLMs) to determine example difficulty. GAIN-RL uses a readily available internal model signal.\n",
       "\n",
       "**News/Announcements:**\n",
       "\n",
       "*   The website announces a new course: **\"Building and Evaluating Data Agents\"**.\n",
       "*   It also highlights the availability of the **GAIN-RL code on GitHub**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://www.deeplearning.ai/the-batch/new-technique-auto-selects-training-examples-to-speed-up-fine-tuning/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf6f4-adce-45e9-97ad-d9a5d7a3a624",
   "metadata": {},
   "source": [
    "# Let's try more websites\n",
    "\n",
    "Note that this will only work on websites that can be scraped using this simplistic approach.\n",
    "\n",
    "Websites that are rendered with Javascript, like React apps, won't show up. See the community-contributions folder for a Selenium implementation that gets around this. You'll need to read up on installing Selenium (ask ChatGPT!)\n",
    "\n",
    "Also Websites protected with CloudFront (and similar) may give 403 errors - many thanks Andy J for pointing this out.\n",
    "\n",
    "But many websites will work just fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45d83403-a24c-44b5-84ac-961449b4008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This website is the homepage of CNN (Cable News Network), a major global news organization. It provides breaking news, the latest updates, and videos across a wide range of categories, including:\n",
       "\n",
       "*   **General News:** US, World, Politics, Business, Health, Entertainment, Style, Travel, Sports, Science, Climate, and Weather.\n",
       "*   **Specific Conflicts:** Ukraine-Russia War, Israel-Hamas War.\n",
       "*   **Features and Series:** As Equals, Call to Earth, Freedom Project, Impact Your World, Inside Africa, CNN Heroes.\n",
       "*   **Media:** Live TV, CNN Fast, Shows A-Z, CNN10, CNN Max, CNN TV Schedules, Podcasts.\n",
       "*   **Interactive Content:** Games (crosswords, sudoku, quizzes).\n",
       "*   **Account Services:** Options to sign in, manage accounts, settings, and subscribe to newsletters.\n",
       "\n",
       "**Key News and Announcements Highlighted:**\n",
       "\n",
       "*   **US Government Shutdown Fears:** Congress has a limited time to avert a shutdown, with \"odds not looking good.\"\n",
       "*   **Trump's Political Activities:** Mentions of Trump addressing the military, posting an AI-generated video, and his potential policies on \"insane asylums.\"\n",
       "*   **Afghanistan Internet Blackout:** A \"total internet blackout\" in Afghanistan has caused panic following Taliban vows to combat \"immoral activities.\"\n",
       "*   **Middle East Peace Efforts:** Analysis on Trump's new Middle East peace plan and the complexities of a Gaza ceasefire.\n",
       "*   **Drone Presence in Korea:** The US is establishing a new Reaper drone unit near China.\n",
       "*   **\"Dumbphone\" Comeback:** The article notes a resurgence of simpler mobile phones, described as \"more exclusive and expensive.\"\n",
       "*   **Celebrity News:** Reports on the separation of Nicole Kidman and Keith Urban, Michelle Pfeiffer becoming a grandmother, and Taylor Swift's significant numbers.\n",
       "*   **Environmental Issues:** Namibia is deploying the army to combat a devastating wildfire in a game reserve.\n",
       "*   **Crime and Investigations:** An ongoing investigation into a shooting at a Michigan church and legal proceedings against Sean \"Diddy\" Combs.\n",
       "*   **Economic Indicators:** Non-scientific indicators like hot dogs and camping trips are being used to gauge the economy.\n",
       "*   **Health News:** A report on the \"devastating impact\" of US abortion restrictions and new findings on heart disease detection.\n",
       "*   **Sports News:** Discussion of a major soccer team's long-distance travel for a Champions League match and a boxer's encounter with police.\n",
       "*   **Arts and Culture:** Features on \"Made in Italy\" fashion and unique travel destinations.\n",
       "*   **Global Events:** Mysterious UAV sightings in Denmark and the ongoing impact of historical events like \"I am Charlie.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9fd40-b354-4341-991e-863ef2e59db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2942642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "/* Modern card-based design */\n",
       ".summary-card {\n",
       "    background: #ffffff;\n",
       "    border-radius: 12px;\n",
       "    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\n",
       "    padding: 24px;\n",
       "    margin: 16px 0;\n",
       "    border: 1px solid #e5e7eb;\n",
       "}\n",
       "\n",
       "/* Enhanced header styling */\n",
       ".summary-header {\n",
       "    color: #1f2937;\n",
       "    font-size: 28px;\n",
       "    font-weight: 700;\n",
       "    margin-bottom: 8px;\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       ".summary-subtitle {\n",
       "    color: #6b7280;\n",
       "    font-size: 14px;\n",
       "    margin-bottom: 24px;\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       "/* Form section styling */\n",
       ".form-section {\n",
       "    background: #f9fafb;\n",
       "    border-radius: 8px;\n",
       "    padding: 20px;\n",
       "    margin-bottom: 20px;\n",
       "    border-left: 4px solid #3b82f6;\n",
       "}\n",
       "\n",
       ".form-label {\n",
       "    color: #374151;\n",
       "    font-weight: 600;\n",
       "    margin-bottom: 8px;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       "/* Enhanced input styling */\n",
       ".url-input-container {\n",
       "    margin-bottom: 16px;\n",
       "}\n",
       "\n",
       ".url-input {\n",
       "    width: 100%;\n",
       "    padding: 12px 16px;\n",
       "    border: 2px solid #d1d5db;\n",
       "    border-radius: 8px;\n",
       "    font-size: 16px;\n",
       "    transition: border-color 0.2s ease;\n",
       "}\n",
       "\n",
       ".url-input:focus {\n",
       "    outline: none;\n",
       "    border-color: #3b82f6;\n",
       "    box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);\n",
       "}\n",
       "\n",
       "/* Button styling */\n",
       ".button-container {\n",
       "    display: flex;\n",
       "    gap: 12px;\n",
       "    justify-content: center;\n",
       "    margin: 20px 0;\n",
       "}\n",
       "\n",
       ".primary-button {\n",
       "    background: linear-gradient(135deg, #3b82f6, #1d4ed8);\n",
       "    color: white;\n",
       "    border: none;\n",
       "    padding: 12px 32px;\n",
       "    border-radius: 8px;\n",
       "    font-weight: 600;\n",
       "    cursor: pointer;\n",
       "    transition: all 0.2s ease;\n",
       "    box-shadow: 0 2px 4px rgba(59, 130, 246, 0.2);\n",
       "}\n",
       "\n",
       ".primary-button:hover {\n",
       "    background: linear-gradient(135deg, #2563eb, #1e40af);\n",
       "    transform: translateY(-1px);\n",
       "    box-shadow: 0 4px 8px rgba(59, 130, 246, 0.3);\n",
       "}\n",
       "\n",
       ".primary-button:disabled {\n",
       "    background: #9ca3af;\n",
       "    cursor: not-allowed;\n",
       "    transform: none;\n",
       "    box-shadow: none;\n",
       "}\n",
       "\n",
       "/* Status and progress styling */\n",
       ".status-section {\n",
       "    background: #fefce8;\n",
       "    border: 1px solid #fbbf24;\n",
       "    border-radius: 8px;\n",
       "    padding: 12px 16px;\n",
       "    margin: 16px 0;\n",
       "}\n",
       "\n",
       ".status-text {\n",
       "    color: #92400e;\n",
       "    font-size: 14px;\n",
       "    margin: 0;\n",
       "}\n",
       "\n",
       ".progress-section {\n",
       "    background: #f0f9ff;\n",
       "    border: 1px solid #0ea5e9;\n",
       "    border-radius: 8px;\n",
       "    padding: 12px 16px;\n",
       "    margin: 16px 0;\n",
       "}\n",
       "\n",
       ".progress-text {\n",
       "    color: #0c4a6e;\n",
       "    font-size: 14px;\n",
       "    margin: 0;\n",
       "}\n",
       "\n",
       "/* Output section styling */\n",
       ".output-section {\n",
       "    background: #f8fafc;\n",
       "    border-radius: 8px;\n",
       "    padding: 20px;\n",
       "    margin-top: 20px;\n",
       "    border: 1px solid #e2e8f0;\n",
       "}\n",
       "\n",
       ".output-header {\n",
       "    color: #334155;\n",
       "    font-size: 18px;\n",
       "    font-weight: 600;\n",
       "    margin-bottom: 16px;\n",
       "    border-bottom: 2px solid #e2e8f0;\n",
       "    padding-bottom: 8px;\n",
       "}\n",
       "\n",
       "/* Style the summary output area */\n",
       ".summary-output-container {\n",
       "    background: #f8fafc;\n",
       "    border-radius: 8px;\n",
       "    padding: 20px;\n",
       "    margin-top: 20px;\n",
       "    border: 1px solid #e2e8f0;\n",
       "    min-height: 100px;\n",
       "}\n",
       "\n",
       "/* Error styling */\n",
       ".error-section {\n",
       "    background: #fef2f2;\n",
       "    border: 1px solid #f87171;\n",
       "    border-radius: 8px;\n",
       "    padding: 12px 16px;\n",
       "    margin: 16px 0;\n",
       "}\n",
       "\n",
       ".error-text {\n",
       "    color: #dc2626;\n",
       "    font-size: 14px;\n",
       "    margin: 0;\n",
       "}\n",
       "\n",
       "/* Success styling */\n",
       ".success-section {\n",
       "    background: #f0fdf4;\n",
       "    border: 1px solid #22c55e;\n",
       "    border-radius: 8px;\n",
       "    padding: 12px 16px;\n",
       "    margin: 16px 0;\n",
       "}\n",
       "\n",
       ".success-text {\n",
       "    color: #15803d;\n",
       "    font-size: 14px;\n",
       "    margin: 0;\n",
       "}\n",
       "\n",
       "/* Responsive design */\n",
       "@media (max-width: 768px) {\n",
       "    .summary-card {\n",
       "        padding: 16px;\n",
       "        margin: 8px 0;\n",
       "    }\n",
       "\n",
       "    .button-container {\n",
       "        flex-direction: column;\n",
       "    }\n",
       "\n",
       "    .primary-button {\n",
       "        width: 100%;\n",
       "    }\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554ccd7b07994cbaa1a506b370d73d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n<div style=\"text-align: center; margin-bottom: 16px;\">\\n    <img src=\"https://img…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create a simple UI\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import threading\n",
    "\n",
    "# %% cell 31 code\n",
    "\n",
    "# Initialize the Gemini model for the UI\n",
    "model = genai.GenerativeModel('models/gemini-2.5-flash-lite')\n",
    "\n",
    "# Enhanced CSS styling for modern UI - displayed separately\n",
    "from IPython.display import HTML\n",
    "css_styles = HTML(\"\"\"\n",
    "<style>\n",
    "/* Modern card-based design */\n",
    ".summary-card {\n",
    "    background: #ffffff;\n",
    "    border-radius: 12px;\n",
    "    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\n",
    "    padding: 24px;\n",
    "    margin: 16px 0;\n",
    "    border: 1px solid #e5e7eb;\n",
    "}\n",
    "\n",
    "/* Enhanced header styling */\n",
    ".summary-header {\n",
    "    color: #1f2937;\n",
    "    font-size: 28px;\n",
    "    font-weight: 700;\n",
    "    margin-bottom: 8px;\n",
    "    text-align: center;\n",
    "}\n",
    "\n",
    ".summary-subtitle {\n",
    "    color: #6b7280;\n",
    "    font-size: 14px;\n",
    "    margin-bottom: 24px;\n",
    "    text-align: center;\n",
    "}\n",
    "\n",
    "/* Form section styling */\n",
    ".form-section {\n",
    "    background: #f9fafb;\n",
    "    border-radius: 8px;\n",
    "    padding: 20px;\n",
    "    margin-bottom: 20px;\n",
    "    border-left: 4px solid #3b82f6;\n",
    "}\n",
    "\n",
    ".form-label {\n",
    "    color: #374151;\n",
    "    font-weight: 600;\n",
    "    margin-bottom: 8px;\n",
    "    display: block;\n",
    "}\n",
    "\n",
    "/* Enhanced input styling */\n",
    ".url-input-container {\n",
    "    margin-bottom: 16px;\n",
    "}\n",
    "\n",
    ".url-input {\n",
    "    width: 100%;\n",
    "    padding: 12px 16px;\n",
    "    border: 2px solid #d1d5db;\n",
    "    border-radius: 8px;\n",
    "    font-size: 16px;\n",
    "    transition: border-color 0.2s ease;\n",
    "}\n",
    "\n",
    ".url-input:focus {\n",
    "    outline: none;\n",
    "    border-color: #3b82f6;\n",
    "    box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);\n",
    "}\n",
    "\n",
    "/* Button styling */\n",
    ".button-container {\n",
    "    display: flex;\n",
    "    gap: 12px;\n",
    "    justify-content: center;\n",
    "    margin: 20px 0;\n",
    "}\n",
    "\n",
    ".primary-button {\n",
    "    background: linear-gradient(135deg, #3b82f6, #1d4ed8);\n",
    "    color: white;\n",
    "    border: none;\n",
    "    padding: 12px 32px;\n",
    "    border-radius: 8px;\n",
    "    font-weight: 600;\n",
    "    cursor: pointer;\n",
    "    transition: all 0.2s ease;\n",
    "    box-shadow: 0 2px 4px rgba(59, 130, 246, 0.2);\n",
    "}\n",
    "\n",
    ".primary-button:hover {\n",
    "    background: linear-gradient(135deg, #2563eb, #1e40af);\n",
    "    transform: translateY(-1px);\n",
    "    box-shadow: 0 4px 8px rgba(59, 130, 246, 0.3);\n",
    "}\n",
    "\n",
    ".primary-button:disabled {\n",
    "    background: #9ca3af;\n",
    "    cursor: not-allowed;\n",
    "    transform: none;\n",
    "    box-shadow: none;\n",
    "}\n",
    "\n",
    "/* Status and progress styling */\n",
    ".status-section {\n",
    "    background: #fefce8;\n",
    "    border: 1px solid #fbbf24;\n",
    "    border-radius: 8px;\n",
    "    padding: 12px 16px;\n",
    "    margin: 16px 0;\n",
    "}\n",
    "\n",
    ".status-text {\n",
    "    color: #92400e;\n",
    "    font-size: 14px;\n",
    "    margin: 0;\n",
    "}\n",
    "\n",
    ".progress-section {\n",
    "    background: #f0f9ff;\n",
    "    border: 1px solid #0ea5e9;\n",
    "    border-radius: 8px;\n",
    "    padding: 12px 16px;\n",
    "    margin: 16px 0;\n",
    "}\n",
    "\n",
    ".progress-text {\n",
    "    color: #0c4a6e;\n",
    "    font-size: 14px;\n",
    "    margin: 0;\n",
    "}\n",
    "\n",
    "/* Output section styling */\n",
    ".output-section {\n",
    "    background: #f8fafc;\n",
    "    border-radius: 8px;\n",
    "    padding: 20px;\n",
    "    margin-top: 20px;\n",
    "    border: 1px solid #e2e8f0;\n",
    "}\n",
    "\n",
    ".output-header {\n",
    "    color: #334155;\n",
    "    font-size: 18px;\n",
    "    font-weight: 600;\n",
    "    margin-bottom: 16px;\n",
    "    border-bottom: 2px solid #e2e8f0;\n",
    "    padding-bottom: 8px;\n",
    "}\n",
    "\n",
    "/* Style the summary output area */\n",
    ".summary-output-container {\n",
    "    background: #f8fafc;\n",
    "    border-radius: 8px;\n",
    "    padding: 20px;\n",
    "    margin-top: 20px;\n",
    "    border: 1px solid #e2e8f0;\n",
    "    min-height: 100px;\n",
    "}\n",
    "\n",
    "/* Error styling */\n",
    ".error-section {\n",
    "    background: #fef2f2;\n",
    "    border: 1px solid #f87171;\n",
    "    border-radius: 8px;\n",
    "    padding: 12px 16px;\n",
    "    margin: 16px 0;\n",
    "}\n",
    "\n",
    ".error-text {\n",
    "    color: #dc2626;\n",
    "    font-size: 14px;\n",
    "    margin: 0;\n",
    "}\n",
    "\n",
    "/* Success styling */\n",
    ".success-section {\n",
    "    background: #f0fdf4;\n",
    "    border: 1px solid #22c55e;\n",
    "    border-radius: 8px;\n",
    "    padding: 12px 16px;\n",
    "    margin: 16px 0;\n",
    "}\n",
    "\n",
    ".success-text {\n",
    "    color: #15803d;\n",
    "    font-size: 14px;\n",
    "    margin: 0;\n",
    "}\n",
    "\n",
    "/* Responsive design */\n",
    "@media (max-width: 768px) {\n",
    "    .summary-card {\n",
    "        padding: 16px;\n",
    "        margin: 8px 0;\n",
    "    }\n",
    "\n",
    "    .button-container {\n",
    "        flex-direction: column;\n",
    "    }\n",
    "\n",
    "    .primary-button {\n",
    "        width: 100%;\n",
    "    }\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "# Display CSS styles first\n",
    "display(css_styles)\n",
    "\n",
    "# Create UI elements\n",
    "\n",
    "# Header section with logo\n",
    "logo_html = widgets.HTML('''\n",
    "<div style=\"text-align: center; margin-bottom: 16px;\">\n",
    "    <img src=\"https://img.icons8.com/fluency/96/000000/web.png\" alt=\"Website Summarizer Logo\"\n",
    "         style=\"width: 64px; height: 64px; margin-bottom: 8px; border-radius: 50%;\">\n",
    "</div>\n",
    "''')\n",
    "\n",
    "header = widgets.HTML('<div class=\"summary-card\"><h1 class=\"summary-header\">🌐 Website Summarizer</h1><p class=\"summary-subtitle\">Powered by Google\\'s Gemini AI</p>')\n",
    "\n",
    "# Form section\n",
    "form_section = widgets.HTML('<div class=\"form-section\"><label class=\"form-label\">Website URL</label><div class=\"url-input-container\">')\n",
    "\n",
    "url_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='https://example.com',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "# Button section\n",
    "button_section = widgets.HTML('<div class=\"button-container\">')\n",
    "submit_button = widgets.Button(\n",
    "    description='🚀 Summarize Website',\n",
    "    disabled=False,\n",
    "    button_style='primary',\n",
    "    tooltip='Click to summarize the website',\n",
    "    layout=widgets.Layout(width='auto')\n",
    ")\n",
    "button_section_close = widgets.HTML('</div></div>')\n",
    "\n",
    "# Status and progress sections\n",
    "status_section = widgets.HTML('<div class=\"status-section\" style=\"display: none;\"><p class=\"status-text\">Enter a URL and click Summarize</p></div>')\n",
    "progress_section = widgets.HTML('<div class=\"progress-section\" style=\"display: none;\"><p class=\"progress-text\">⏳ Processing...</p></div>')\n",
    "\n",
    "# Output section container\n",
    "output_container = widgets.HTML('<div class=\"summary-output-container\" style=\"display: none;\">')\n",
    "summary_output = widgets.Output()\n",
    "output_close = widgets.HTML('</div>')\n",
    "\n",
    "def on_button_click(b):\n",
    "    url = url_input.value.strip()\n",
    "    if not url:\n",
    "        # Show error state\n",
    "        status_section.value = '<div class=\"status-section\"><p class=\"error-text\">❌ Please enter a valid URL.</p></div>'\n",
    "        progress_section.value = '<div class=\"progress-section\" style=\"display: none;\"><p class=\"progress-text\">⏳ Processing...</p></div>'\n",
    "        output_container.value = '<div class=\"summary-output-container\" style=\"display: none;\">'\n",
    "        return\n",
    "\n",
    "    # Show processing state\n",
    "    status_section.value = '<div class=\"status-section\" style=\"display: none;\"><p class=\"status-text\">Enter a URL and click Summarize</p></div>'\n",
    "    progress_section.value = '<div class=\"progress-section\"><p class=\"progress-text\">⏳ Analyzing website content...</p></div>'\n",
    "    output_container.value = '<div class=\"summary-output-container\" style=\"display: none;\">'\n",
    "    submit_button.disabled = True\n",
    "\n",
    "    # Run summarization in a separate thread to avoid blocking\n",
    "    def summarize_in_thread():\n",
    "        try:\n",
    "            summary = summarize(url)\n",
    "\n",
    "            # Show success state\n",
    "            progress_section.value = '<div class=\"progress-section\"><p class=\"progress-text\">✅ Summary generated successfully!</p></div>'\n",
    "            status_section.value = f'<div class=\"status-section\"><p class=\"success-text\">📝 Summary ready for: {url}</p></div>'\n",
    "\n",
    "            # Show output section with summary and website info\n",
    "            output_container.value = '<div class=\"summary-output-container\">'\n",
    "\n",
    "            # Display website favicon and basic info\n",
    "            website = Website(url)\n",
    "            favicon_html = \"\"\n",
    "            if website.favicon:\n",
    "                favicon_html = f'''\n",
    "                <div style=\"text-align: center; margin-bottom: 16px; padding: 12px; background: #f8fafc; border-radius: 8px; border: 1px solid #e2e8f0;\">\n",
    "                    <img src=\"{website.favicon}\" alt=\"Website favicon\" style=\"width: 32px; height: 32px; margin-right: 8px; vertical-align: middle; border-radius: 4px;\">\n",
    "                    <strong style=\"color: #374151;\">{website.title}</strong>\n",
    "                </div>\n",
    "                '''\n",
    "\n",
    "            # Display main images if available\n",
    "            images_html = \"\"\n",
    "            if website.images:\n",
    "                images_html = '<div style=\"margin: 16px 0; text-align: center;\">'\n",
    "                for i, img in enumerate(website.images[:2]):  # Show max 2 images\n",
    "                    images_html += f'''\n",
    "                    <div style=\"display: inline-block; margin: 8px; text-align: center;\">\n",
    "                        <img src=\"{img['url']}\" alt=\"{img['alt']}\" style=\"max-width: 200px; max-height: 150px; border-radius: 8px; border: 1px solid #e2e8f0;\">\n",
    "                        <p style=\"font-size: 12px; color: #6b7280; margin-top: 4px; max-width: 200px; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;\">{img['alt'] or 'Website image'}</p>\n",
    "                    </div>\n",
    "                    '''\n",
    "                images_html += '</div>'\n",
    "\n",
    "            # Display the summary in the output widget\n",
    "            with summary_output:\n",
    "                clear_output()\n",
    "                # Show favicon and images first\n",
    "                if favicon_html or images_html:\n",
    "                    display(HTML(favicon_html + images_html))\n",
    "                # Then show the summary\n",
    "                display(Markdown(summary))\n",
    "\n",
    "        except Exception as e:\n",
    "            # Show error state\n",
    "            progress_section.value = '<div class=\"progress-section\"><p class=\"progress-text\">❌ Error occurred during summarization</p></div>'\n",
    "            status_section.value = f'<div class=\"status-section\"><p class=\"error-text\">⚠️ Could not summarize: {url}. Please check the URL and try again.</p></div>'\n",
    "\n",
    "            # Show output section with error details\n",
    "            output_container.value = '<div class=\"summary-output-container\">'\n",
    "\n",
    "            with summary_output:\n",
    "                clear_output()\n",
    "                error_details = widgets.HTML(f'<p style=\"color: #6b7280; font-size: 12px; margin-top: 8px;\">Error details: {str(e)}</p>')\n",
    "                display(error_details)\n",
    "\n",
    "        finally:\n",
    "            submit_button.disabled = False\n",
    "\n",
    "    thread = threading.Thread(target=summarize_in_thread)\n",
    "    thread.daemon = True\n",
    "    thread.start()\n",
    "\n",
    "submit_button.on_click(on_button_click)\n",
    "\n",
    "# Create layout - modern card-based design\n",
    "ui = widgets.VBox([\n",
    "    # Logo and main content sections\n",
    "    logo_html,\n",
    "    header,\n",
    "    form_section,\n",
    "    url_input,\n",
    "    button_section,\n",
    "    submit_button,\n",
    "    button_section_close,\n",
    "\n",
    "    # Status and progress sections\n",
    "    status_section,\n",
    "    progress_section,\n",
    "\n",
    "    # Output section\n",
    "    output_container,\n",
    "    summary_output,\n",
    "    output_close\n",
    "])\n",
    "\n",
    "# Display the UI\n",
    "display(ui)\n",
    "\n",
    "\n",
    "# %% cell 32 markdown\n",
    "\n",
    "# ## How to use:\n",
    "# \n",
    "# 1. Enter a website URL in the text field\n",
    "# 2. Click the \"Summarize\" button\n",
    "# 3. Wait for the summary to appear below\n",
    "# \n",
    "# The UI will show progress and status messages. This works with the same websites as the original function (no JavaScript-heavy sites or CloudFront-protected sites).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
